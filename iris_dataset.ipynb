{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "destroyed-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from typing import Any, Dict, List, Iterable, Tuple, Union\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import leabra7 as lb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets, sklearn.metrics, sklearn.model_selection, sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "operating-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoggerType = Union[None, logging.Logger, logging.LoggerAdapter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "central-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(num_feature_units: int = 10,\n",
    "              logger: LoggerType = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads and preprocesses the data.\n",
    "    \n",
    "    Returns:\n",
    "        An (X, Y) tuple containing the features and labels, respectively.\n",
    "    \"\"\"\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger()\n",
    "    logger.info(\"Loading data\")\n",
    "    data = sklearn.datasets.load_iris()\n",
    "    \n",
    "    # One-hot encode the labels\n",
    "    label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    Y = label_binarizer.fit_transform(data.target)\n",
    "    \n",
    "    # Quantile transform, bin, and one-hot encode the features\n",
    "    quant = sklearn.preprocessing.QuantileTransformer()\n",
    "    X = quant.fit_transform(data.data)\n",
    "    X = np.digitize(X, bins=np.linspace(0.0, 1.0, num=num_feature_units))\n",
    "    one_hot = sklearn.preprocessing.OneHotEncoder(sparse=False)\n",
    "    X = one_hot.fit_transform(X)\n",
    "    \n",
    "    # Randomly shuffle the data\n",
    "    return sklearn.utils.shuffle(X, Y)\n",
    "\n",
    "\n",
    "def build_network(input_size: int,\n",
    "                  output_size: int,\n",
    "                  hidden_size: int = 23,\n",
    "                  logger: LoggerType = None) -> lb.Net:\n",
    "    \"\"\"Builds the classifier network.\n",
    "    \n",
    "    Args:\n",
    "        input_size: The size of the input layer.\n",
    "        output_size: The size of the output layer.\n",
    "        hidden_size: The size of the hidden layer.\n",
    "        logger: The logger to use.\n",
    "    \n",
    "    Returns:\n",
    "        A Leabra7 network for classification.\n",
    "    \"\"\"\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger()\n",
    "    logger.info(\"Building network\")\n",
    "    net = lb.Net()\n",
    "    \n",
    "    # Layers\n",
    "    layer_spec = lb.LayerSpec(gi=1.5, ff=1, fb=1,\n",
    "    unit_spec=lb.UnitSpec(spike_gain=0, vm_gain=0, adapt_dt=0))\n",
    "    net.new_layer(\"input\", size=input_size, spec=layer_spec)\n",
    "    net.new_layer(\"hidden\", size=hidden_size, spec=layer_spec)\n",
    "    net.new_layer(\"output\", size=output_size, spec=layer_spec)\n",
    "    logger.debug(\"Input layer size: %d\", input_size)\n",
    "    logger.debug(\"Hidden layer size: %d\", hidden_size)\n",
    "    logger.debug(\"Output layer size: %d\", output_size)\n",
    "    \n",
    "    # Projections\n",
    "    lrate = 0.02\n",
    "    up_spec = lb.ProjnSpec(\n",
    "        lrate=lrate,\n",
    "        dist=lb.Uniform(0.25, 0.75),\n",
    "        cos_diff_thr_l_mix=False,\n",
    "        cos_diff_lrate=False)\n",
    "    down_spec = lb.ProjnSpec(\n",
    "        lrate=lrate,\n",
    "        dist=lb.Uniform(0.25, 0.5),\n",
    "        wt_scale_rel=0.3,\n",
    "        cos_diff_thr_l_mix=False,\n",
    "        cos_diff_lrate=False)\n",
    "    net.new_projn(\n",
    "        \"input_to_hidden\", pre=\"input\", post=\"hidden\", spec=up_spec)\n",
    "    net.new_projn(\n",
    "        \"hidden_to_output\", pre=\"hidden\", post=\"output\", spec=up_spec)\n",
    "    net.new_projn(\n",
    "        \"output_to_hidden\", pre=\"output\", post=\"hidden\", spec=down_spec)\n",
    "    \n",
    "    return net\n",
    "\n",
    "def trial(network: lb.Net, input_pattern: Iterable[float],\n",
    "          output_pattern: Iterable[float]) -> None:\n",
    "    \"\"\"Runs a trial.\n",
    "    \n",
    "    Args:\n",
    "        input_pattern: The pattern to clamp to the network's input layer.\n",
    "        output_pattern: The pattern to clamp to the network's output layer.\n",
    "    \"\"\"\n",
    "    network.clamp_layer(\"input\", input_pattern)\n",
    "    network.minus_phase_cycle(num_cycles=50)\n",
    "    network.clamp_layer(\"output\", output_pattern)\n",
    "    network.plus_phase_cycle(num_cycles=25)\n",
    "    network.unclamp_layer(\"input\")\n",
    "    network.unclamp_layer(\"output\")\n",
    "    network.learn()\n",
    "    \n",
    "def epoch(network: lb.Net, input_patterns: np.ndarray,\n",
    "          output_patterns: np.ndarray) -> None:\n",
    "    \"\"\"Runs an epoch (one pass through the whole dataset).\n",
    "    \n",
    "    Args:\n",
    "        input_patterns: A numpy array with shape (n_samples, n_features).\n",
    "        output_patterns: A numpy array with shape (n_samples, n_features).\n",
    "    \"\"\"\n",
    "    for x, y in zip(input_patterns, output_patterns):\n",
    "        trial(network, x, y)\n",
    "    network.end_epoch()\n",
    "    \n",
    "def train(network: lb.Net,\n",
    "          input_patterns: np.ndarray,\n",
    "          output_patterns: np.ndarray,\n",
    "          num_epochs: int = 500,\n",
    "          logger: LoggerType = None) -> pd.DataFrame:\n",
    "    \"\"\"Trains the network.\n",
    "    \n",
    "    Args:\n",
    "        input_patterns: A numpy array with shape (n_samples, n_features).\n",
    "        output_patterns: A numpy array with shape (n_samples, n_features).\n",
    "        num_patterns: The number of epochs to run. Defaults to 500.\n",
    "        logger: The logger to use. If None, will use the module's default logger.\n",
    "    \n",
    "    Returns:\n",
    "        29pd.DataFrame:\n",
    "        A dataframe of metrics from the training run.\n",
    "    \"\"\"\n",
    "    if logger is None:\n",
    "        logger = logging.getLogger()\n",
    "    logger.info(\"Begin training\")\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(\n",
    "        input_patterns, output_patterns, test_size=0.2)\n",
    "    \n",
    "    logger.debug(\"Training set size: %d\", X_train.shape[0])\n",
    "    logger.debug(\"Test set size: %d\", X_test.shape[0])\n",
    "    \n",
    "    data: Dict[str, List[float]] = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_accuracy\": []\n",
    "    }\n",
    "        \n",
    "    for i in range(num_epochs):\n",
    "        epoch(network, X_train, Y_train)\n",
    "        # Predicting is slow, so we only calculate metrics every 5 epochs\n",
    "        if (i + 1) % 5 == 0:\n",
    "            pred_train = predict(network, X_train)\n",
    "            data[\"epoch\"].append(i)\n",
    "            data[\"train_loss\"].append(\n",
    "                sklearn.metrics.mean_squared_error(Y_train, pred_train))\n",
    "            data[\"train_accuracy\"].append(\n",
    "                sklearn.metrics.accuracy_score(\n",
    "                    Y_train, pred_train, normalize=True))\n",
    "            pred_test = predict(network, X_test)\n",
    "            data[\"test_loss\"].append(\n",
    "                sklearn.metrics.mean_squared_error(Y_test, pred_test))\n",
    "            data[\"test_accuracy\"].append(\n",
    "                sklearn.metrics.accuracy_score(\n",
    "                    Y_test, pred_test, normalize=True))\n",
    "            logger.info(\n",
    "                \"Epoch %d/%d. Train accuracy: %.2f%%. Test accuracy: %.2f%%\",\n",
    "                i, num_epochs, data[\"train_accuracy\"][-1] * 100,\n",
    "                data[\"test_accuracy\"][-1] * 100)\n",
    "    logger.info(\"End training\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def output(network: lb.Net, pattern: Iterable[float]) -> List[float]:\n",
    "    \"\"\"Calculates a prediction for a single input pattern.\n",
    "    \n",
    "    Args:\n",
    "        network: The trained network.\n",
    "        pattern: The input pattern.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The output of the network after clamping the input\n",
    "        pattern to the input layer and settling. The max value is set to one,\n",
    "        everything else is set to zero.\n",
    "    \"\"\"\n",
    "    network.clamp_layer(\"input\", pattern)\n",
    "    for _ in range(50):\n",
    "        network.cycle()\n",
    "    network.unclamp_layer(\"input\")\n",
    "    out = network.observe(\"output\", \"unit_act\")[\"act\"].values\n",
    "    max_idx = np.argmax(out)\n",
    "    out[:] = 0\n",
    "    out[max_idx] = 1\n",
    "    return list(out)\n",
    "\n",
    "def predict(network: lb.Net, input_patterns: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Calculates predictions for an array of input patterns.\n",
    "    \n",
    "    Args:\n",
    "        network: The trained network.\n",
    "        input_patterns: An array of shape (n_samples, n_features)\n",
    "        containing the input patterns for which to calculate predictions.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of shape (n_samples, n_features) containing the\n",
    "        predictions for the input patterns.\n",
    "    \"\"\"\n",
    "    outputs = [output(network, item)\n",
    "               for item in input_patterns]\n",
    "    return np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sapphire-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-07 12:50:26,405 INFO Begin training iris\n"
     ]
    }
   ],
   "source": [
    "PROJ_NAME = \"iris\"\n",
    "np.seterr(\"warn\")\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    handlers=(\n",
    "        logging.FileHandler(\n",
    "            \"{0}_log.txt\".format(PROJ_NAME), mode=\"w\"),\n",
    "        logging.StreamHandler(sys.stdout)))\n",
    "\n",
    "logging.info(\"Begin training %s\", PROJ_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fantastic-parade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-07 12:50:28,156 INFO Loading data\n",
      "2021-04-07 12:50:28,165 INFO Building network\n",
      "2021-04-07 12:50:28,168 DEBUG Input layer size: 40\n",
      "2021-04-07 12:50:28,169 DEBUG Hidden layer size: 23\n",
      "2021-04-07 12:50:28,169 DEBUG Output layer size: 3\n",
      "2021-04-07 12:50:28,172 INFO Begin training\n",
      "2021-04-07 12:50:28,174 DEBUG Training set size: 120\n",
      "2021-04-07 12:50:28,174 DEBUG Test set size: 30\n",
      "2021-04-07 12:51:57,871 INFO Epoch 4/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 12:53:23,466 INFO Epoch 9/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 12:54:53,598 INFO Epoch 14/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 12:56:23,700 INFO Epoch 19/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 12:57:53,768 INFO Epoch 24/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 12:59:31,506 INFO Epoch 29/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:01:01,881 INFO Epoch 34/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:02:25,392 INFO Epoch 39/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:03:42,732 INFO Epoch 44/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:05:14,118 INFO Epoch 49/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:06:39,056 INFO Epoch 54/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:08:00,299 INFO Epoch 59/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:09:21,745 INFO Epoch 64/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:10:43,165 INFO Epoch 69/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:12:04,552 INFO Epoch 74/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:13:26,271 INFO Epoch 79/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:14:48,345 INFO Epoch 84/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:16:10,677 INFO Epoch 89/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:17:32,683 INFO Epoch 94/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:18:54,598 INFO Epoch 99/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:20:16,626 INFO Epoch 104/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:21:38,918 INFO Epoch 109/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:23:00,421 INFO Epoch 114/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:24:22,361 INFO Epoch 119/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:25:43,648 INFO Epoch 124/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:27:05,813 INFO Epoch 129/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:28:28,328 INFO Epoch 134/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:29:50,754 INFO Epoch 139/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:31:13,209 INFO Epoch 144/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:32:35,631 INFO Epoch 149/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:33:58,260 INFO Epoch 154/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:35:20,901 INFO Epoch 159/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:36:43,307 INFO Epoch 164/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:38:06,175 INFO Epoch 169/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:39:28,710 INFO Epoch 174/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:40:52,037 INFO Epoch 179/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:42:14,601 INFO Epoch 184/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:43:24,233 INFO Epoch 189/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:44:32,581 INFO Epoch 194/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:45:41,107 INFO Epoch 199/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:46:50,491 INFO Epoch 204/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:47:59,111 INFO Epoch 209/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:49:08,094 INFO Epoch 214/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:50:17,062 INFO Epoch 219/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:51:25,884 INFO Epoch 224/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:52:34,675 INFO Epoch 229/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:53:43,913 INFO Epoch 234/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:54:53,069 INFO Epoch 239/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:56:02,494 INFO Epoch 244/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:57:11,606 INFO Epoch 249/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:58:20,877 INFO Epoch 254/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 13:59:29,710 INFO Epoch 259/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:00:38,399 INFO Epoch 264/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:01:47,165 INFO Epoch 269/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:02:55,749 INFO Epoch 274/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:04:04,273 INFO Epoch 279/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:05:12,831 INFO Epoch 284/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:06:21,574 INFO Epoch 289/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:07:30,548 INFO Epoch 294/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:08:39,548 INFO Epoch 299/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:09:48,671 INFO Epoch 304/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:10:57,862 INFO Epoch 309/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:12:06,819 INFO Epoch 314/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:13:15,567 INFO Epoch 319/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:14:24,102 INFO Epoch 324/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:15:32,446 INFO Epoch 329/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:16:41,230 INFO Epoch 334/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:17:50,227 INFO Epoch 339/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:18:59,034 INFO Epoch 344/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:20:08,304 INFO Epoch 349/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:21:17,888 INFO Epoch 354/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:22:26,991 INFO Epoch 359/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:23:37,772 INFO Epoch 364/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:24:56,274 INFO Epoch 369/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:26:22,213 INFO Epoch 374/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:27:38,652 INFO Epoch 379/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n",
      "2021-04-07 14:28:54,686 INFO Epoch 384/500. Train accuracy: 35.83%. Test accuracy: 16.67%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f13decc2cf24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     output_size=Y.shape[1])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Save metrics and network for future analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3be802af624a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, input_patterns, output_patterns, num_epochs, logger)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;31m# Predicting is slow, so we only calculate metrics every 5 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3be802af624a>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(network, input_patterns, output_patterns)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_patterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_patterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mtrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3be802af624a>\u001b[0m in \u001b[0;36mtrial\u001b[0;34m(network, input_pattern, output_pattern)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminus_phase_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cycles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplus_phase_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cycles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munclamp_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munclamp_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/Leabra7-0.1.dev1-py3.8.egg/leabra7/net.py\u001b[0m in \u001b[0;36mplus_phase_cycle\u001b[0;34m(self, num_cycles)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeginPlusPhase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndPlusPhase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEndTrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/Leabra7-0.1.dev1-py3.8.egg/leabra7/net.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;34m\"\"\"Overrides events.EventListnerMixin.handle()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/Leabra7-0.1.dev1-py3.8.egg/leabra7/net.py\u001b[0m in \u001b[0;36m_cycle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m\"\"\"Cycles the network (triggered by cycle event).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/Leabra7-0.1.dev1-py3.8.egg/leabra7/layer.py\u001b[0m in \u001b[0;36mactivation_cycle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cycle_learning_averages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwt_scale_rel_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/Leabra7-0.1.dev1-py3.8.egg/leabra7/unit.py\u001b[0m in \u001b[0;36mupdate_cycle_learning_averages\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m         self.avg_ss += self.spec.integ * self.spec.ss_dt * (\n\u001b[1;32m    294\u001b[0m             self.act - self.avg_ss)\n\u001b[0;32m--> 295\u001b[0;31m         self.avg_s += self.spec.integ * self.spec.s_dt * (\n\u001b[0m\u001b[1;32m    296\u001b[0m             self.avg_ss - self.avg_s)\n\u001b[1;32m    297\u001b[0m         self.avg_m += self.spec.integ * self.spec.m_dt * (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, Y = load_data()\n",
    "net = build_network(\n",
    "    input_size=X.shape[1],\n",
    "    output_size=Y.shape[1])\n",
    "\n",
    "metrics = train(net, X, Y)\n",
    "\n",
    "# Save metrics and network for future analysis\n",
    "metrics.to_csv(\"{0}_metrics.csv\".format(PROJ_NAME), index=False)\n",
    "net.save(\"{0}_network.pkl\".format(PROJ_NAME))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
